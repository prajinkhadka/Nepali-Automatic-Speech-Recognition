{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc31deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, load_metric,Dataset,concatenate_datasets,set_caching_enabled, ClassLabel\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import json\n",
    "from transformers import Wav2Vec2CTCTokenizer,Wav2Vec2ForCTC,Wav2Vec2Processor,Trainer,TrainingArguments,Wav2Vec2FeatureExtractor\n",
    "\n",
    "import re\n",
    "set_caching_enabled(False)\n",
    "\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['WANDB_DISABLED '] = 'True'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76cb785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import transformers\n",
    "transformers.logging.get_verbosity = lambda: logging.NOTSET\n",
    "\n",
    "transformers.logging.get_verbosity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a173c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "datasets.logging.get_verbosity = lambda: logging.NOTSET\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec18a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('/workspace/data/Nepali_Openslr_Train_labelled1_13-08-2021_11-46/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7814fd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audioFilename</th>\n",
       "      <th>collectionSource</th>\n",
       "      <th>snr</th>\n",
       "      <th>duration</th>\n",
       "      <th>gender</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00024e9ee7.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>दुष्यन्तका नजिक पुग्दछन्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002f96e3e.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>अध्यक्ष पनि हुनुहुन्छ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004a4f6e2.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>प्रवेश गर्न</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000515a639.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>गरेका थिए जुन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0012875eae.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>मिसन विशेषज्ञ थिइन्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22187</th>\n",
       "      <td>fff32477bb.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>परम्परागत रूपबाट क्षेत्ररक्षण</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22188</th>\n",
       "      <td>fff3f152cb.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>राज्यको रूपमा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22189</th>\n",
       "      <td>fffac91bc2.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>बाइबलको दोश्रो पुस्तक</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22190</th>\n",
       "      <td>fffd7ed065.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>दशकका बेला अस्ट्रेलियाली</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22191</th>\n",
       "      <td>fffda46dff.wav</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>त्यस्तै गरी पूर्व</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        audioFilename                                   collectionSource  \\\n",
       "0      00024e9ee7.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "1      0002f96e3e.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "2      0004a4f6e2.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "3      000515a639.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "4      0012875eae.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "...               ...                                                ...   \n",
       "22187  fff32477bb.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22188  fff3f152cb.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22189  fffac91bc2.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22190  fffd7ed065.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22191  fffda46dff.wav  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "\n",
       "                                                     snr  duration  \\\n",
       "0      {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "1      {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "2      {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "3      {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "4      {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "...                                                  ...       ...   \n",
       "22187  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22188  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22189  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22190  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22191  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "\n",
       "              gender                           text  \n",
       "0      non-specified       दुष्यन्तका नजिक पुग्दछन्  \n",
       "1      non-specified          अध्यक्ष पनि हुनुहुन्छ  \n",
       "2      non-specified                    प्रवेश गर्न  \n",
       "3      non-specified                  गरेका थिए जुन  \n",
       "4      non-specified            मिसन विशेषज्ञ थिइन्  \n",
       "...              ...                            ...  \n",
       "22187  non-specified  परम्परागत रूपबाट क्षेत्ररक्षण  \n",
       "22188  non-specified                  राज्यको रूपमा  \n",
       "22189  non-specified          बाइबलको दोश्रो पुस्तक  \n",
       "22190  non-specified       दशकका बेला अस्ट्रेलियाली  \n",
       "22191  non-specified              त्यस्तै गरी पूर्व  \n",
       "\n",
       "[22192 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f11de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    file = \"/workspace/data/Nepali_Openslr_Train_labelled1_13-08-2021_11-46/\" + data['audioFilename'][i]\n",
    "    data['audioFilename'][i] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb283f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/data/Nepali_Openslr_Train_labelled1_13-08-2021_11-46/0002f96e3e.wav'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['audioFilename'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8d5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'text':'sentence'}, inplace = True)\n",
    "data.rename(columns = {'audioFilename':'path'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a727a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = data[0:10000], data[-1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db7d267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>collectionSource</th>\n",
       "      <th>snr</th>\n",
       "      <th>duration</th>\n",
       "      <th>gender</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>दुष्यन्तका नजिक पुग्दछन्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>अध्यक्ष पनि हुनुहुन्छ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>प्रवेश गर्न</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>गरेका थिए जुन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>मिसन विशेषज्ञ थिइन्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>प्रस्तुत गरेकी छन्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>गर्ने भोज खुवाउने</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>वैज्ञानिक जोडबाट विकास</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>राहु तथा शनि</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>रमाई बस्ने</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  \\\n",
       "0     /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "1     /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "2     /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "3     /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "4     /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "...                                                 ...   \n",
       "9995  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "9996  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "9997  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "9998  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "9999  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "\n",
       "                                       collectionSource  \\\n",
       "0     [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "1     [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "2     [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "3     [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "4     [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "...                                                 ...   \n",
       "9995  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "9996  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "9997  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "9998  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "9999  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "\n",
       "                                                    snr  duration  \\\n",
       "0     {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "1     {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "2     {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "3     {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "4     {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "...                                                 ...       ...   \n",
       "9995  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "9996  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "9997  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "9998  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "9999  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "\n",
       "             gender                  sentence  \n",
       "0     non-specified  दुष्यन्तका नजिक पुग्दछन्  \n",
       "1     non-specified     अध्यक्ष पनि हुनुहुन्छ  \n",
       "2     non-specified               प्रवेश गर्न  \n",
       "3     non-specified             गरेका थिए जुन  \n",
       "4     non-specified       मिसन विशेषज्ञ थिइन्  \n",
       "...             ...                       ...  \n",
       "9995  non-specified        प्रस्तुत गरेकी छन्  \n",
       "9996  non-specified         गर्ने भोज खुवाउने  \n",
       "9997  non-specified    वैज्ञानिक जोडबाट विकास  \n",
       "9998  non-specified              राहु तथा शनि  \n",
       "9999  non-specified                रमाई बस्ने  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68cbab35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>collectionSource</th>\n",
       "      <th>snr</th>\n",
       "      <th>duration</th>\n",
       "      <th>gender</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21192</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>यस्तो स्थिति पुग्दा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21193</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>तल्लो डुङ्गेश्वर दैलेख</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21194</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>कसैको आशा इच्छा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21195</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>आन्तरिक पर्यटकमा पनि</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21196</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>र सुत्केरी भएका बेला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22187</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>परम्परागत रूपबाट क्षेत्ररक्षण</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22188</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>राज्यको रूपमा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22189</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>बाइबलको दोश्रो पुस्तक</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22190</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>दशकका बेला अस्ट्रेलियाली</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22191</th>\n",
       "      <td>/workspace/data/Nepali_Openslr_Train_labelled1...</td>\n",
       "      <td>[Nepali_Openslr_Train_labelled1, unknown, unkn...</td>\n",
       "      <td>{'methodType': 'WadaSnr', 'methodDetails': {'s...</td>\n",
       "      <td>5</td>\n",
       "      <td>non-specified</td>\n",
       "      <td>त्यस्तै गरी पूर्व</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  \\\n",
       "21192  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "21193  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "21194  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "21195  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "21196  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "...                                                  ...   \n",
       "22187  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "22188  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "22189  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "22190  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "22191  /workspace/data/Nepali_Openslr_Train_labelled1...   \n",
       "\n",
       "                                        collectionSource  \\\n",
       "21192  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "21193  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "21194  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "21195  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "21196  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "...                                                  ...   \n",
       "22187  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22188  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22189  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22190  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "22191  [Nepali_Openslr_Train_labelled1, unknown, unkn...   \n",
       "\n",
       "                                                     snr  duration  \\\n",
       "21192  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "21193  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "21194  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "21195  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "21196  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "...                                                  ...       ...   \n",
       "22187  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22188  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22189  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22190  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "22191  {'methodType': 'WadaSnr', 'methodDetails': {'s...         5   \n",
       "\n",
       "              gender                       sentence  \n",
       "21192  non-specified            यस्तो स्थिति पुग्दा  \n",
       "21193  non-specified         तल्लो डुङ्गेश्वर दैलेख  \n",
       "21194  non-specified                कसैको आशा इच्छा  \n",
       "21195  non-specified           आन्तरिक पर्यटकमा पनि  \n",
       "21196  non-specified           र सुत्केरी भएका बेला  \n",
       "...              ...                            ...  \n",
       "22187  non-specified  परम्परागत रूपबाट क्षेत्ररक्षण  \n",
       "22188  non-specified                  राज्यको रूपमा  \n",
       "22189  non-specified          बाइबलको दोश्रो पुस्तक  \n",
       "22190  non-specified       दशकका बेला अस्ट्रेलियाली  \n",
       "22191  non-specified              त्यस्तै गरी पूर्व  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1354f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train_1 = Dataset.from_pandas(train[5000:])\n",
    "common_voice_train_2 = Dataset.from_pandas(train[0:5000])\n",
    "\n",
    "common_voice_test = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb58296",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train_1 = common_voice_train_1.remove_columns([ \"collectionSource\",\"snr\",  \"duration\", \"gender\"])\n",
    "common_voice_train_2 = common_voice_train_2.remove_columns([\"collectionSource\",\"snr\",  \"duration\", \"gender\"])\n",
    "\n",
    "common_voice_test = common_voice_test.remove_columns([ \"collectionSource\",\"snr\",  \"duration\", \"gender\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d164c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'sentence'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48fc5fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3275820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec542e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>जीवनयापन पद्धतिमा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>रूपले अधिकार थियो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>रहेको यो ताल</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>पाँच वर्षको हुँदा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>दशक पछि अधिकांश</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>नाम तेह्रथुम जिल्लाको</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>क्षेत्रको एक अञ्चल हो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>भएमा बिमार निको</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>पृथ्वीलाई दुहुँदै सबै</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>जनगणना अनुसार दुलीको</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>एक उपाय हो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>गर्ने सम्पूर्ण नेपाली</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>विकले माओवादीको भातृ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>सुन्दरता र उर्जावान</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>भोकमरीले अकालमा नमारोस्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>गर्नुको बदलामा सो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>आवश्यक पर्ने बारुद</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>एकेन्द्रजी तपाईँलाई तेह्रथुम</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>लागेको मङ्गोल शासक</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>आउने बादलले गर्दा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(common_voice_train_1.remove_columns([\"path\"]), num_examples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd73810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a89da404",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train_1 = common_voice_train_1.map(remove_special_characters)\n",
    "common_voice_train_2 = common_voice_train_2.map(remove_special_characters)\n",
    "\n",
    "common_voice_test = common_voice_test.map(remove_special_characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82d0e5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>सँग मिलाएर दिनाले</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>बोधक शब्दको</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>भेटको छ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>यो डाक्टर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>अन्य रानीहरू पनि</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>भारत आउनु पर् यो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>उनका दुई छोरा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>नै उसको अमरत्वको</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>लेङ्गा हो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>पढाउने काम पहिले</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(common_voice_train_1.remove_columns([\"path\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43010039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"sentence\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bc4ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_train_2 = common_voice_train_2.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train_2.column_names)\n",
    "\n",
    "vocab_train_1 = common_voice_train_1.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train_1.column_names)\n",
    "vocab_test = common_voice_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95910d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(set(vocab_train_2[\"vocab\"][0]) |set(vocab_train_1[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "118776dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ड': 0,\n",
       " 'इ': 1,\n",
       " 'ढ': 2,\n",
       " 'फ': 3,\n",
       " 'ठ': 4,\n",
       " 'ृ': 5,\n",
       " 'ः': 6,\n",
       " ' ': 7,\n",
       " 'औ': 8,\n",
       " 'द': 9,\n",
       " 'ञ': 10,\n",
       " 'ं': 11,\n",
       " 'ऋ': 12,\n",
       " 'घ': 13,\n",
       " 'अ': 14,\n",
       " 'ई': 15,\n",
       " 'ट': 16,\n",
       " 'ग': 17,\n",
       " 'ँ': 18,\n",
       " 'झ': 19,\n",
       " 'ै': 20,\n",
       " 'ि': 21,\n",
       " 'ह': 22,\n",
       " '्': 23,\n",
       " 'छ': 24,\n",
       " 'ष': 25,\n",
       " 'ङ': 26,\n",
       " 'प': 27,\n",
       " 'ऐ': 28,\n",
       " 'र': 29,\n",
       " 'े': 30,\n",
       " 'ऊ': 31,\n",
       " 'ब': 32,\n",
       " 'थ': 33,\n",
       " 'व': 34,\n",
       " 'उ': 35,\n",
       " 'भ': 36,\n",
       " 'ी': 37,\n",
       " 'ज': 38,\n",
       " 'ए': 39,\n",
       " 'ा': 40,\n",
       " 'त': 41,\n",
       " 'आ': 42,\n",
       " 'ख': 43,\n",
       " 'ल': 44,\n",
       " 'ो': 45,\n",
       " 'ु': 46,\n",
       " 'क': 47,\n",
       " 'स': 48,\n",
       " 'ओ': 49,\n",
       " 'ध': 50,\n",
       " 'ण': 51,\n",
       " 'म': 52,\n",
       " 'श': 53,\n",
       " 'न': 54,\n",
       " 'ू': 55,\n",
       " 'ौ': 56,\n",
       " 'च': 57,\n",
       " 'य': 58,\n",
       " 'ॠ': 59}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48489be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe1d6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b37041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc0855ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70815b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5585373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f72ed069",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(\"./ASR WOLOF Data/wav2vec2-large-xlsr-WOLOF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f9c398c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/workspace/data/Nepali_Openslr_Train_labelled1_13-08-2021_11-46/3a1e8dfa63.wav',\n",
       " 'sentence': 'वायु र वनस्पति '}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_train_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f26394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = sf.read(batch[\"path\"])\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"sentence\"]\n",
    "    return batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aab4c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train_1 = common_voice_train_1.map(speech_file_to_array_fn, remove_columns=common_voice_train_1.column_names,num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18abbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train_2 = common_voice_train_2.map(speech_file_to_array_fn, remove_columns=common_voice_train_2.column_names,num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "877b37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_test = common_voice_test.map(speech_file_to_array_fn, remove_columns=common_voice_test.column_names,num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b45422",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'common_voice_train_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1beb0a111c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrand_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_voice_train_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_voice_train_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_int\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"speech\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'common_voice_train_1' is not defined"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(common_voice_train_1)-1)\n",
    "\n",
    "ipd.Audio(data=np.asarray(common_voice_train_1[rand_int][\"speech\"]), autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c10d8e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target text: हो जुन अन्तरिक्षमा \n",
      "Input array shape: (44800,)\n",
      "Sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "rand_int = random.randint(0, len(common_voice_train_1)-1)\n",
    "\n",
    "print(\"Target text:\", common_voice_train_1[rand_int][\"target_text\"])\n",
    "print(\"Input array shape:\", np.asarray(common_voice_train_1[rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", common_voice_train_1[rand_int][\"sampling_rate\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e81afa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f11f1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train_1 = common_voice_train_1.map(prepare_dataset, remove_columns=common_voice_train_1.column_names, batch_size=8, num_proc=4, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a0431eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train_2 = common_voice_train_2.map(prepare_dataset, remove_columns=common_voice_train_2.column_names, batch_size=8, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e284ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names, batch_size=8, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cfcf1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train = concatenate_datasets([common_voice_train_1, common_voice_train_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b7108d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c61f571c6947f1896d631431d67fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "# repo_name = \"wav2vec2-large-xls-r-300m-tr-colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "390c5e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_values', 'labels'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "357bf003",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"wav2vec2-large-xlsr-53-nepali-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8243dabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test into local empty directory.\n",
      "To https://huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test\n",
      "   6a26171..c463c96  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test/commit/c463c9693fb53c1dbe5ed71e5ee4c709e55d00a9'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1861442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a805a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e679b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26eaf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6d6f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd993c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-xls-r-300m were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'project_q.bias', 'quantizer.codevectors', 'project_q.weight', 'project_hid.bias', 'project_hid.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-xls-r-300m\", \n",
    "    attention_dropout=0.0,\n",
    "    hidden_dropout=0.0,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.0,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbf14acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55f4adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=repo_name,\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=16,\n",
    "  gradient_accumulation_steps=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=50,\n",
    "  gradient_checkpointing=True,\n",
    "  fp16=True,\n",
    "  save_steps=400,\n",
    "  eval_steps=400,\n",
    "  logging_steps=400,\n",
    "  learning_rate=3e-4,\n",
    "  warmup_steps=500,\n",
    "  save_total_limit=2,\n",
    "  push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea42b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wav2vec2-large-xlsr-53-nepali-test is already a clone of https://huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "485c49e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 15600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15600' max='15600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15600/15600 6:37:20, Epoch 49/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.782100</td>\n",
       "      <td>3.205204</td>\n",
       "      <td>1.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.944300</td>\n",
       "      <td>0.733775</td>\n",
       "      <td>1.030093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.516457</td>\n",
       "      <td>0.914908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.554300</td>\n",
       "      <td>0.449785</td>\n",
       "      <td>0.855067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>0.447191</td>\n",
       "      <td>0.813905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.407070</td>\n",
       "      <td>0.793843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.421016</td>\n",
       "      <td>0.789692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.437923</td>\n",
       "      <td>0.769284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.398253</td>\n",
       "      <td>0.752335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>0.753718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.416548</td>\n",
       "      <td>0.731927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.424718</td>\n",
       "      <td>0.740228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.421158</td>\n",
       "      <td>0.738845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.180200</td>\n",
       "      <td>0.435917</td>\n",
       "      <td>0.724663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.449930</td>\n",
       "      <td>0.729159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.422637</td>\n",
       "      <td>0.726046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.433912</td>\n",
       "      <td>0.731927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.434390</td>\n",
       "      <td>0.716707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.445083</td>\n",
       "      <td>0.721550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.421626</td>\n",
       "      <td>0.719474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.447136</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.471793</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.703217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.514536</td>\n",
       "      <td>0.712902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.711519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.510141</td>\n",
       "      <td>0.702871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.464526</td>\n",
       "      <td>0.694223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.466572</td>\n",
       "      <td>0.696645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.464769</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.686960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.461085</td>\n",
       "      <td>0.694915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.452538</td>\n",
       "      <td>0.696299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.470250</td>\n",
       "      <td>0.688343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.482169</td>\n",
       "      <td>0.688343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.472174</td>\n",
       "      <td>0.689381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.457813</td>\n",
       "      <td>0.681079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.463733</td>\n",
       "      <td>0.679696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.465604</td>\n",
       "      <td>0.679350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.460128</td>\n",
       "      <td>0.678312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-1200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-1200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-1200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-1200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-1600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-1600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-1600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-1600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-2000\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2000/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2000/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-1200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-2400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-1600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-2800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-2800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-3200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-3200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-3200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-3200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-2400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-3600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-3600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-3600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-3600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-2800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-4000\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4000/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4000/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-3200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-4400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-3600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-4800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-4800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-4000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-5200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-5200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-5200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-5200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-4400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-5600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-5600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-5600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-5600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-4800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-6000\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6000/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6000/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-5200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-6400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-5600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-6800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-6800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-6000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-7200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-7200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-7200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-7200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-6400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-7600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-7600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-7600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-7600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-6800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-8000\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8000/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8000/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-7200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-8400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-7600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-8800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-8800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-8000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-9200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-9200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-9200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-9200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-8400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-9600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-9600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-9600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-9600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-8800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-10000\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10000/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10000/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-9200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-10400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-9600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-10800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-10800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-11200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-11200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-11200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-11200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-10400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-11600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-11600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-11600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-11600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-10800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-12000\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12000/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12000/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-11200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-12400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-11600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-12800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-12800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-12000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-13200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-13200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-13200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-13200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-12400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-13600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-13600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-13600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-13600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-12800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-14000\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14000/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14000/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14000/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-13200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-14400\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14400/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14400/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14400/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-13600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-14800\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14800/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14800/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-14800/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-14000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-15200\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-15200/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-15200/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-15200/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-14400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test/checkpoint-15600\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-15600/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-15600/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/checkpoint-15600/preprocessor_config.json\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-53-nepali-test/checkpoint-14800] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15600, training_loss=0.4148120795763456, metrics={'train_runtime': 23844.4548, 'train_samples_per_second': 20.969, 'train_steps_per_second': 0.654, 'total_flos': 5.392776008679628e+19, 'train_loss': 0.4148120795763456, 'epoch': 50.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a13a71a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to wav2vec2-large-xlsr-53-nepali-test\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/config.json\n",
      "Model weights saved in wav2vec2-large-xlsr-53-nepali-test/pytorch_model.bin\n",
      "Configuration saved in wav2vec2-large-xlsr-53-nepali-test/preprocessor_config.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{}\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5f128fe3bc4e32a5eaf91441835791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 3.37k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at 8e67e001b62eb40c479fb905d24d4cde3bc0dd51 but expected 74fc628cfeb1aa20cdd0d4dbe0514c92971bd386        \n",
      "To https://huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://user: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@huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test'\n",
      "\n",
      "Error pushing update to the model card. Please read logs and retry.\n",
      "$remote: error: cannot lock ref 'refs/heads/main': is at 8e67e001b62eb40c479fb905d24d4cde3bc0dd51 but expected 74fc628cfeb1aa20cdd0d4dbe0514c92971bd386        \n",
      "To https://huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://user: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@huggingface.co/prajin/wav2vec2-large-xlsr-53-nepali-test'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7807e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "reponame = \"wav2vec2-large-xlsr-53-nepali-test\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained(reponame).to(\"cuda\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(reponame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16b9f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2ForCTC(\n",
      "  (wav2vec2): Wav2Vec2Model(\n",
      "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Wav2Vec2LayerNormConvLayer(\n",
      "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Wav2Vec2LayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): Wav2Vec2LayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): Wav2Vec2LayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): Wav2Vec2LayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): Wav2Vec2LayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): Wav2Vec2LayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (feature_projection): Wav2Vec2FeatureProjection(\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
      "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
      "        (padding): Wav2Vec2SamePadLayer()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (12): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (13): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (14): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (15): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (16): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (17): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (18): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (19): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (20): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (21): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (22): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (23): Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (lm_head): Linear(in_features=1024, out_features=62, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a56ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
